AWSTemplateFormatVersion: '2010-09-09'
Description: SlideRule Cluster

##############################
Parameters:

  Domain:
    Type: String

  ClusterName:
    Type: String

  Organization:
    Type: String

  ProjectBucket:
    Type: String

  ProjectFolder:
    Type: String

  ProjectPublicBucket:
    Type: String

  ContainerRepo:
    Type: String

  #
  # Constants
  #

  ManagerIP:
    Type: String
    Default: "10.0.1.3"

  MonitorIP:
    Type: String
    Default: "10.0.1.4"

  IlbIP:
    Type: String
    Default: "10.0.1.5"

  AvailabilityZone:
    Type: String
    Default: "us-west-2d"

  PublicCIDRBlock:
    Type: String
    Default: "0.0.0.0/0"

  VpcCIDRBlock:
    Type: String
    Default: "10.0.0.0/16"

  NodeCapacity:
    Type: Number
    Default: 7

  ImageId:
    Type: String
    Default: !Sub "{{resolve:ssm:/ami/sliderule/arm/latest}}"

##############################
Resources:

  #
  # Cluster Network
  #

  SlideruleVPC:
    Type: AWS::EC2::VPC
    Properties:
      CidrBlock: !Ref VpcCIDRBlock
      EnableDnsSupport: true
      EnableDnsHostnames: true
      Tags:
        - Key: Name
          Value: !Sub "${ClusterName}-vpc"

  SlideruleSubnet:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref SlideruleVPC
      CidrBlock: "10.0.0.0/16"
      MapPublicIpOnLaunch: true
      AvailabilityZone: !Ref AvailabilityZone
      Tags:
        - Key: Name
          Value: !Sub "${ClusterName}-subnet"

  SlideruleIGW:
    Type: AWS::EC2::InternetGateway
    Properties:
      Tags:
        - Key: Name
          Value: !Sub "${ClusterName}-gateway"

  AttachIGW:
    Type: AWS::EC2::VPCGatewayAttachment
    Properties:
      InternetGatewayId: !Ref SlideruleIGW
      VpcId: !Ref SlideruleVPC

  SlideruleRouteTable:
    Type: AWS::EC2::RouteTable
    Properties:
      VpcId: !Ref SlideruleVPC
      Tags:
        - Key: Name
          Value: !Sub "${Organization}-route"

  SlideruleRoute:
    Type: AWS::EC2::Route
    Properties:
      RouteTableId: !Ref SlideruleRouteTable
      DestinationCidrBlock: "0.0.0.0/0"
      GatewayId: !Ref SlideruleIGW

  RouteAssoc:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId: !Ref SlideruleSubnet
      RouteTableId: !Ref SlideruleRouteTable

  #
  # IAM Roles
  #

  ClusterRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub "${ClusterName}-iam-role"
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - ec2.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly
        - arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore
        - arn:aws:iam::aws:policy/CloudWatchAgentServerPolicy
        - arn:aws:iam::aws:policy/CloudWatchAgentAdminPolicy

  S3ManagedPolicy:
    Type: AWS::IAM::ManagedPolicy
    Properties:
      ManagedPolicyName: !Sub "${ClusterName}-iams3-policy"
      PolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Action: ["s3:ListBucket"]
            Resource:
              - arn:aws:s3:::sliderule
              - arn:aws:s3:::pgc-opendata-dems
              - arn:aws:s3:::prd-tnm
              - arn:aws:s3:::esa-worldcover
              - arn:aws:s3:::noaa-ocs-nationalbathymetry-pds
              - arn:aws:s3:::dataforgood-fb-data
          - Effect: Allow
            Action: ["s3:GetObject"]
            Resource:
              - arn:aws:s3:::sliderule/*
              - arn:aws:s3:::pgc-opendata-dems/*
              - arn:aws:s3:::prd-tnm/*
              - arn:aws:s3:::esa-worldcover/*
              - arn:aws:s3:::noaa-ocs-nationalbathymetry-pds/*
              - arn:aws:s3:::dataforgood-fb-data/*
          - Effect: Allow
            Action: ["s3:PutObject"]
            Resource:
              - !Sub "arn:aws:s3:::${ProjectBucket}/${ProjectFolder}/manager/*"
              - !Sub "arn:aws:s3:::${ProjectPublicBucket}/*"

  EC2ManagedPolicy:
    Type: AWS::IAM::ManagedPolicy
    Properties:
      ManagedPolicyName: !Sub "${ClusterName}-iamec2-policy"
      PolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Action:
              - ec2:DescribeInstances
              - ec2:TerminateInstances
            Resource: "*"

  AttachS3Policy:
    Type: AWS::IAM::RolePolicyAttachment
    Properties:
      Role: !Ref ClusterRole
      PolicyArn: !Ref S3ManagedPolicy

  AttachEC2Policy:
    Type: AWS::IAM::RolePolicyAttachment
    Properties:
      Role: !Ref ClusterRole
      PolicyArn: !Ref EC2ManagedPolicy

  InstanceProfile:
    Type: AWS::IAM::InstanceProfile
    Properties:
      Roles: [!Ref ClusterRole]

  #
  # Security Groups
  #

  MonitorSG:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Monitor Security Group
      VpcId: !Ref SlideruleVPC
      SecurityGroupIngress:
        # Loki (from Promtail)
        - IpProtocol: tcp
          FromPort: 3100
          ToPort: 3100
          CidrIp: !Ref VpcCIDRBlock
        # NGINX (from HAProxy)
        - IpProtocol: tcp
          FromPort: 8040
          ToPort: 8040
          CidrIp: !Ref VpcCIDRBlock
      SecurityGroupEgress:
        # ALL
        - IpProtocol: -1
          FromPort: 0
          ToPort: 0
          CidrIp: !Ref PublicCIDRBlock
      Tags:
        - Key: Name
          Value: !Sub "${ClusterName}-monitor-sg"

  IlbSG:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: ILB Security Group
      VpcId: !Ref SlideruleVPC
      SecurityGroupIngress:
        # HAProxy
        - IpProtocol: tcp
          FromPort: 443
          ToPort: 443
          CidrIp: !Ref PublicCIDRBlock
        # Orchestrator (from HAProxy)
        - IpProtocol: tcp
          FromPort: 8050
          ToPort: 8050
          CidrIp: !Ref VpcCIDRBlock
        # Node Exporter (from Prometheus)
        - IpProtocol: tcp
          FromPort: 9100
          ToPort: 9100
          CidrIp: !Ref VpcCIDRBlock
      SecurityGroupEgress:
        # ALL
        - IpProtocol: -1
          FromPort: 0
          ToPort: 0
          CidrIp: !Ref PublicCIDRBlock
      Tags:
        - Key: Name
          Value: !Sub "${ClusterName}-ilb-sg"

  ManagerSG:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Manager Security Group
      VpcId: !Ref SlideruleVPC
      SecurityGroupIngress:
        # Manager (from HAProxy)
        - IpProtocol: tcp
          FromPort: 8030
          ToPort: 8030
          CidrIp: !Ref VpcCIDRBlock
      SecurityGroupEgress:
        # ALL
        - IpProtocol: -1
          FromPort: 0
          ToPort: 0
          CidrIp: !Ref PublicCIDRBlock
      Tags:
        - Key: Name
          Value: !Sub "${ClusterName}-manager-sg"

  SlideruleSG:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Sliderule app SG
      VpcId: !Ref SlideruleVPC
      SecurityGroupIngress:
        # SlideRule (from HAProxy)
        - IpProtocol: tcp
          FromPort: 9081
          ToPort: 9081
          CidrIp: !Ref VpcCIDRBlock
        # Node Exporter (from Prometheus)
        - IpProtocol: tcp
          FromPort: 9100
          ToPort: 9100
          CidrIp: !Ref VpcCIDRBlock
      SecurityGroupEgress:
        # ALL
        - IpProtocol: -1
          FromPort: 0
          ToPort: 0
          CidrIp: !Ref PublicCIDRBlock
      Tags:
        - Key: Name
          Value: !Sub "${ClusterName}-sliderule-sg"

  #
  # ILB
  #

  IlbInstance:
    Type: AWS::EC2::Instance
    Properties:
      ImageId: !Ref ImageId
      InstanceType: c8g.large
      AvailabilityZone: !Ref AvailabilityZone
      IamInstanceProfile: !Ref InstanceProfile
      SubnetId: !Ref SlideruleSubnet
      PrivateIpAddress: !Ref IlbIP
      SecurityGroupIds:
        - !Ref IlbSecurityGroupId
      SourceDestCheck: true
      Monitoring: false
      AssociatePublicIpAddress: true
      BlockDeviceMappings:
        - DeviceName: /dev/xvda
          Ebs:
            VolumeSize: 40
            VolumeType: gp3
            DeleteOnTermination: true
      Tags:
        - Key: Name
          Value: !Sub "${ClusterName}-ilb"
      UserData:
        Fn::Base64: !Sub |
          #!/bin/bash
          aws ecr get-login-password --region us-west-2 | docker login --username AWS --password-stdin ${ContainerRepo}
          export OAUTH_HMAC_SECRET='${local.secrets.jwt_secret_key}'
          export IS_PUBLIC=${var.is_public}
          export ORGANIZATION=${Organization}
          export DOMAIN=${Domain}
          export ILB_IMAGE=${ContainerRepo}/ilb:${Version}
          mkdir -p /etc/ssl/private
          aws s3 cp s3://${ProjectBucket}/${ProjectFolder}/${Domain}.pem /etc/ssl/private/${Domain}.pem
          aws s3 cp s3://${ProjectBucket}/${ProjectFolder}/docker-compose-ilb.yml ./docker-compose.yml
          docker-compose -p cluster up --detach

  #
  # Manager
  #

  ManagerInstance:
    Type: AWS::EC2::Instance
    Properties:
      ImageId: !Ref ImageId
      InstanceType: r8g.large
      AvailabilityZone: !Ref AvailabilityZone
      SubnetId: !Ref SlideruleSubnet
      IamInstanceProfile: !Ref InstanceProfile
      PrivateIpAddress: !Ref ManagerIP
      SecurityGroupIds: [ !Ref ManagerSecurityGroupId ]
      SourceDestCheck: true
      Monitoring: false
      AssociatePublicIpAddress: true
      BlockDeviceMappings:
        - DeviceName: /dev/xvda
          Ebs:
            VolumeSize: 40
            VolumeType: gp3
            DeleteOnTermination: true
      Tags:
        - Key: Name
          Value: !Sub "${ClusterName}-manager"
      UserData:
        Fn::Base64: !Sub |
          #!/bin/bash
          echo ${ClusterName} > ./clustername.txt
          aws ecr get-login-password --region us-west-2 | docker login --username AWS --password-stdin ${ContainerRepo}
          export IS_PUBLIC=${var.is_public}
          export DOMAIN=${Domain}
          export MANAGER_SECRET_SALT='${local.secrets.manager_secret_salt}'
          export MANAGER_API_KEY='${local.secrets.manager_api_key}'
          export DUCKDB_LOCAL_FILE='/data/manager-${ClusterName}.db'
          export DUCKDB_REMOTE_FILE='s3://${ProjectBucket}/${ProjectFolder}/manager/manager-${Organization}-${Version}.db'
          export MANAGER_IMAGE=${ContainerRepo}/manager:${ClusterVersion}
          mkdir /data
          aws s3 cp $DUCKDB_REMOTE_FILE $DUCKDB_LOCAL_FILE || true
          aws s3 cp s3://${ProjectBucket}/${ProjectFolder}/GeoLite2-ASN.mmdb /data/GeoLite2-ASN.mmdb
          aws s3 cp s3://${ProjectBucket}/${ProjectFolder}/GeoLite2-City.mmdb /data/GeoLite2-City.mmdb
          aws s3 cp s3://${ProjectBucket}/${ProjectFolder}/GeoLite2-Country.mmdb /data/GeoLite2-Country.mmdb
          aws s3 cp s3://${ProjectBucket}/${ProjectFolder}/docker-compose-manager.yml ./docker-compose.yml
          docker-compose -p cluster up --detach

  #
  # Monitor
  #

  MonitorInstance:
    Type: AWS::EC2::Instance
    Properties:
      ImageId: !Ref ImageId
      InstanceType: c8g.large
      AvailabilityZone: !Ref AvailabilityZone
      SubnetId: !Ref SlideruleSubnet
      IamInstanceProfile: !Ref InstanceProfile
      PrivateIpAddress: !Ref MonitorIP
      SecurityGroupIds:
        - !Ref MonitorSecurityGroupId
      SourceDestCheck: true
      Monitoring: false
      AssociatePublicIpAddress: true
      BlockDeviceMappings:
        - DeviceName: /dev/xvda
          Ebs:
            VolumeSize: 40
            VolumeType: gp3
            DeleteOnTermination: true
      Tags:
        - Key: Name
          Value: !Sub "${ClusterName}-monitor"
      UserData:
        Fn::Base64: !Sub |
          #!/bin/bash
          echo ${ClusterName} > ./clustername.txt
          aws ecr get-login-password --region us-west-2 | docker login --username AWS --password-stdin ${ContainerRepo}
          export CLIENT_ID='${local.secrets.client_id}'
          export CLIENT_SECRET='${local.secrets.client_secret}'
          export DOMAIN=${Domain}
          export MONITOR_IMAGE=${ContainerRepo}/monitor:${Version}
          export PROXY_IMAGE=${ContainerRepo}/proxy:${Version}
          aws s3 cp s3://${ProjectBucket}/${ProjectFolder}/docker-compose-monitor.yml ./docker-compose.yml
          docker-compose -p cluster up --detach

  #
  # Autoscaling Group
  #

  SlideruleLaunchTemplate:
    Type: AWS::EC2::LaunchTemplate
    Properties:
      LaunchTemplateName: !Sub "${ClusterName}-lt"
      LaunchTemplateData:
        ImageId: !Ref ImageId
        InstanceType: t4g.2xlarge
        IamInstanceProfile:
          Name: !Ref InstanceProfileName
        NetworkInterfaces:
          - AssociatePublicIpAddress: true
            DeviceIndex: 0
            Groups:
              - !Ref SecurityGroupId
        BlockDeviceMappings:
          - DeviceName: "/dev/xvda"
            Ebs:
              VolumeSize: !Ref ClusterVolumeSize
              VolumeType: gp2
              DeleteOnTermination: true
        UserData:
          Fn::Base64: !Sub |
            #!/bin/bash
            export ENVIRONMENT_VERSION=${EnvironmentVersion}
            export IPV4=$(hostname -I | awk '{print $1}')
            export ORGANIZATION=${Organization}
            export CLUSTER=${ClusterName}
            export IS_PUBLIC=${var.is_public}
            export SLIDERULE_IMAGE=${ContainerRepo}/sliderule:${Version}
            export AMS_IMAGE=${ContainerRepo}/ams:${Version}
            export PROVISIONING_SYSTEM="https://ps.${Domain}"
            export CONTAINER_REGISTRY=${ContainerRepo}
            aws ecr get-login-password --region us-west-2 | docker login --username AWS --password-stdin ${ContainerRepo}
            mkdir -p /data/ATL13
            aws s3 cp s3://${ProjectBucket}/${ProjectFolder}/atl13_mappings.json /data/ATL13/atl13_mappings.json
            aws s3 cp s3://${ProjectBucket}/${ProjectFolder}/inland_water_body.db /data/ATL13/inland_water_body.db
            aws s3 cp s3://${ProjectBucket}/plugins/ /plugins/ --recursive
            aws s3 cp s3://${ProjectBucket}/${ProjectFolder}/docker-compose-node.yml ./docker-compose.yml
            docker-compose -p cluster up --detach

  SlideruleAutoScalingGroup:
    Type: AWS::AutoScaling::AutoScalingGroup
    Properties:
      AutoScalingGroupName: !Sub "${ClusterName}-asg"
      MinSize: !Ref NodeCapacity
      MaxSize: !Ref NodeCapacity
      DesiredCapacity: !Ref NodeCapacity
      VPCZoneIdentifier:
        - !Ref SubnetId
      HealthCheckType: EC2
      CapacityRebalance: true
      LaunchTemplate:
        LaunchTemplateId: !Ref SlideruleLaunchTemplate
        Version: !GetAtt SlideruleLaunchTemplate.LatestVersionNumber
      Tags:
        - Key: Name
          Value: !Sub "${ClusterName}-node"
          PropagateAtLaunch: true

  #
  # Route53
  #

  IlbRecord:
    Type: AWS::Route53::RecordSet
    Properties:
      HostedZoneName: !Sub "${Domain}."   # ensure trailing dot or you can pass HostedZoneId instead
      Name: !Sub "${ClusterName}.${Domain}"
      Type: A
      TTL: "300"
      ResourceRecords:
        - !GetAtt IlbInstance.PublicIp